{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\LENOVO\\\\OneDrive\\\\Documents\\\\Alice\\\\frontend\\\\src\\\\App.js\",\n  _s = $RefreshSig$();\nimport { useState, useRef, useEffect } from \"react\";\nimport Orb from \"./Orb\";\nimport \"./App.css\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\nexport default function App() {\n  _s();\n  const [listening, setListening] = useState(false);\n  const [speaking, setSpeaking] = useState(false);\n  const recognitionRef = useRef(null);\n\n  // Setup speech recognition ONCE\n  useEffect(() => {\n    if (!SpeechRecognition) {\n      alert(\"Speech Recognition not supported in this browser\");\n      return;\n    }\n    const recognition = new SpeechRecognition();\n    recognition.lang = \"en-US\";\n    recognition.interimResults = false;\n    recognition.continuous = false;\n    recognition.onresult = async event => {\n      const transcript = event.results[0][0].transcript;\n      setListening(false);\n\n      // Send text to backend\n      const res = await fetch(\"http://localhost:8000/chat\", {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify({\n          message: transcript\n        })\n      });\n      const data = await res.json();\n      speak(data.response);\n    };\n    recognition.onerror = () => setListening(false);\n    recognitionRef.current = recognition;\n  }, []);\n\n  // ðŸŽ™ï¸ Start listening\n  const startListening = () => {\n    if (!recognitionRef.current) return;\n    setListening(true);\n    recognitionRef.current.start();\n  };\n\n  // ðŸ”Š Speak response\n  const speak = text => {\n    // If Alice is already speaking â†’ STOP\n    if (window.speechSynthesis.speaking) {\n      window.speechSynthesis.cancel();\n      setSpeaking(false);\n      return;\n    }\n\n    // Start speaking\n    const utterance = new SpeechSynthesisUtterance(text);\n    utterance.lang = \"en-US\";\n    utterance.rate = 0.95;\n    utterance.pitch = 1.05;\n    utterance.volume = 1;\n    setSpeaking(true);\n    utterance.onend = () => {\n      setSpeaking(false);\n    };\n    window.speechSynthesis.speak(utterance);\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"container\",\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"assistant-name\",\n      children: \"Alice\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 82,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      onClick: startListening,\n      children: /*#__PURE__*/_jsxDEV(Orb, {\n        listening: listening,\n        speaking: speaking\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 86,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 85,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      className: \"mic-button\",\n      onClick: startListening,\n      children: listening ? \"Listeningâ€¦\" : speaking ? \"Speakingâ€¦\" : \"Tap to Speak\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 90,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 80,\n    columnNumber: 5\n  }, this);\n}\n_s(App, \"wJLMVF4Q9spFnf5x/VBZivcOBXA=\");\n_c = App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["useState","useRef","useEffect","Orb","jsxDEV","_jsxDEV","SpeechRecognition","window","webkitSpeechRecognition","App","_s","listening","setListening","speaking","setSpeaking","recognitionRef","alert","recognition","lang","interimResults","continuous","onresult","event","transcript","results","res","fetch","method","headers","body","JSON","stringify","message","data","json","speak","response","onerror","current","startListening","start","text","speechSynthesis","cancel","utterance","SpeechSynthesisUtterance","rate","pitch","volume","onend","className","children","fileName","_jsxFileName","lineNumber","columnNumber","onClick","_c","$RefreshReg$"],"sources":["C:/Users/LENOVO/OneDrive/Documents/Alice/frontend/src/App.js"],"sourcesContent":["import { useState, useRef, useEffect } from \"react\";\nimport Orb from \"./Orb\";\nimport \"./App.css\";\n\nconst SpeechRecognition =\n  window.SpeechRecognition || window.webkitSpeechRecognition;\n\nexport default function App() {\n  const [listening, setListening] = useState(false);\n  const [speaking, setSpeaking] = useState(false);\n\n  const recognitionRef = useRef(null);\n\n  // Setup speech recognition ONCE\n  useEffect(() => {\n    if (!SpeechRecognition) {\n      alert(\"Speech Recognition not supported in this browser\");\n      return;\n    }\n\n    const recognition = new SpeechRecognition();\n    recognition.lang = \"en-US\";\n    recognition.interimResults = false;\n    recognition.continuous = false;\n\n    recognition.onresult = async (event) => {\n      const transcript = event.results[0][0].transcript;\n      setListening(false);\n\n      // Send text to backend\n      const res = await fetch(\"http://localhost:8000/chat\", {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify({ message: transcript }),\n      });\n\n      const data = await res.json();\n      speak(data.response);\n    };\n\n    recognition.onerror = () => setListening(false);\n\n    recognitionRef.current = recognition;\n  }, []);\n\n  // ðŸŽ™ï¸ Start listening\n  const startListening = () => {\n    if (!recognitionRef.current) return;\n    setListening(true);\n    recognitionRef.current.start();\n  };\n\n  // ðŸ”Š Speak response\n  const speak = (text) => {\n  // If Alice is already speaking â†’ STOP\n  if (window.speechSynthesis.speaking) {\n    window.speechSynthesis.cancel();\n    setSpeaking(false);\n    return;\n  }\n\n  // Start speaking\n  const utterance = new SpeechSynthesisUtterance(text);\n\n  utterance.lang = \"en-US\";\n  utterance.rate = 0.95;\n  utterance.pitch = 1.05;\n  utterance.volume = 1;\n\n  setSpeaking(true);\n\n  utterance.onend = () => {\n    setSpeaking(false);\n  };\n\n  window.speechSynthesis.speak(utterance);\n};\n\n  return (\n    <div className=\"container\">\n      {/* Assistant name */}\n      <div className=\"assistant-name\">Alice</div>\n\n      {/* Orb = mic */}\n      <div onClick={startListening}>\n        <Orb listening={listening} speaking={speaking} />\n      </div>\n\n      {/* Button */}\n      <button className=\"mic-button\" onClick={startListening}>\n        {listening\n          ? \"Listeningâ€¦\"\n          : speaking\n          ? \"Speakingâ€¦\"\n          : \"Tap to Speak\"}\n      </button>\n    </div>\n        \n  );\n}\n"],"mappings":";;AAAA,SAASA,QAAQ,EAAEC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AACnD,OAAOC,GAAG,MAAM,OAAO;AACvB,OAAO,WAAW;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEnB,MAAMC,iBAAiB,GACrBC,MAAM,CAACD,iBAAiB,IAAIC,MAAM,CAACC,uBAAuB;AAE5D,eAAe,SAASC,GAAGA,CAAA,EAAG;EAAAC,EAAA;EAC5B,MAAM,CAACC,SAAS,EAAEC,YAAY,CAAC,GAAGZ,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAACa,QAAQ,EAAEC,WAAW,CAAC,GAAGd,QAAQ,CAAC,KAAK,CAAC;EAE/C,MAAMe,cAAc,GAAGd,MAAM,CAAC,IAAI,CAAC;;EAEnC;EACAC,SAAS,CAAC,MAAM;IACd,IAAI,CAACI,iBAAiB,EAAE;MACtBU,KAAK,CAAC,kDAAkD,CAAC;MACzD;IACF;IAEA,MAAMC,WAAW,GAAG,IAAIX,iBAAiB,CAAC,CAAC;IAC3CW,WAAW,CAACC,IAAI,GAAG,OAAO;IAC1BD,WAAW,CAACE,cAAc,GAAG,KAAK;IAClCF,WAAW,CAACG,UAAU,GAAG,KAAK;IAE9BH,WAAW,CAACI,QAAQ,GAAG,MAAOC,KAAK,IAAK;MACtC,MAAMC,UAAU,GAAGD,KAAK,CAACE,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAACD,UAAU;MACjDX,YAAY,CAAC,KAAK,CAAC;;MAEnB;MACA,MAAMa,GAAG,GAAG,MAAMC,KAAK,CAAC,4BAA4B,EAAE;QACpDC,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UAAE,cAAc,EAAE;QAAmB,CAAC;QAC/CC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UAAEC,OAAO,EAAET;QAAW,CAAC;MAC9C,CAAC,CAAC;MAEF,MAAMU,IAAI,GAAG,MAAMR,GAAG,CAACS,IAAI,CAAC,CAAC;MAC7BC,KAAK,CAACF,IAAI,CAACG,QAAQ,CAAC;IACtB,CAAC;IAEDnB,WAAW,CAACoB,OAAO,GAAG,MAAMzB,YAAY,CAAC,KAAK,CAAC;IAE/CG,cAAc,CAACuB,OAAO,GAAGrB,WAAW;EACtC,CAAC,EAAE,EAAE,CAAC;;EAEN;EACA,MAAMsB,cAAc,GAAGA,CAAA,KAAM;IAC3B,IAAI,CAACxB,cAAc,CAACuB,OAAO,EAAE;IAC7B1B,YAAY,CAAC,IAAI,CAAC;IAClBG,cAAc,CAACuB,OAAO,CAACE,KAAK,CAAC,CAAC;EAChC,CAAC;;EAED;EACA,MAAML,KAAK,GAAIM,IAAI,IAAK;IACxB;IACA,IAAIlC,MAAM,CAACmC,eAAe,CAAC7B,QAAQ,EAAE;MACnCN,MAAM,CAACmC,eAAe,CAACC,MAAM,CAAC,CAAC;MAC/B7B,WAAW,CAAC,KAAK,CAAC;MAClB;IACF;;IAEA;IACA,MAAM8B,SAAS,GAAG,IAAIC,wBAAwB,CAACJ,IAAI,CAAC;IAEpDG,SAAS,CAAC1B,IAAI,GAAG,OAAO;IACxB0B,SAAS,CAACE,IAAI,GAAG,IAAI;IACrBF,SAAS,CAACG,KAAK,GAAG,IAAI;IACtBH,SAAS,CAACI,MAAM,GAAG,CAAC;IAEpBlC,WAAW,CAAC,IAAI,CAAC;IAEjB8B,SAAS,CAACK,KAAK,GAAG,MAAM;MACtBnC,WAAW,CAAC,KAAK,CAAC;IACpB,CAAC;IAEDP,MAAM,CAACmC,eAAe,CAACP,KAAK,CAACS,SAAS,CAAC;EACzC,CAAC;EAEC,oBACEvC,OAAA;IAAK6C,SAAS,EAAC,WAAW;IAAAC,QAAA,gBAExB9C,OAAA;MAAK6C,SAAS,EAAC,gBAAgB;MAAAC,QAAA,EAAC;IAAK;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC,eAG3ClD,OAAA;MAAKmD,OAAO,EAAEjB,cAAe;MAAAY,QAAA,eAC3B9C,OAAA,CAACF,GAAG;QAACQ,SAAS,EAAEA,SAAU;QAACE,QAAQ,EAAEA;MAAS;QAAAuC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAE;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC9C,CAAC,eAGNlD,OAAA;MAAQ6C,SAAS,EAAC,YAAY;MAACM,OAAO,EAAEjB,cAAe;MAAAY,QAAA,EACpDxC,SAAS,GACN,YAAY,GACZE,QAAQ,GACR,WAAW,GACX;IAAc;MAAAuC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACZ,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACN,CAAC;AAGV;AAAC7C,EAAA,CA5FuBD,GAAG;AAAAgD,EAAA,GAAHhD,GAAG;AAAA,IAAAgD,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}