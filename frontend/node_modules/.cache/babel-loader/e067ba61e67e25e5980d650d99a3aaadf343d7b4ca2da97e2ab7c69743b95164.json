{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\LENOVO\\\\OneDrive\\\\Documents\\\\Alice\\\\frontend\\\\src\\\\VoiceButton.js\",\n  _s = $RefreshSig$();\nimport { useState } from \"react\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\nexport default function VoiceButton({\n  onResult\n}) {\n  _s();\n  const [listening, setListening] = useState(false);\n  const startListening = () => {\n    if (!SpeechRecognition) {\n      alert(\"Speech Recognition not supported in this browser\");\n      return;\n    }\n    const recognition = new SpeechRecognition();\n    recognition.lang = \"en-US\";\n    recognition.start();\n    setListening(true);\n    recognition.onresult = event => {\n      const transcript = event.results[0][0].transcript;\n      setListening(false);\n      onResult(transcript);\n    };\n    recognition.onerror = () => setListening(false);\n  };\n  return /*#__PURE__*/_jsxDEV(\"button\", {\n    className: `mic-button ${listening ? \"listening\" : \"\"}`,\n    onClick: startListening,\n    children: \"\\uD83C\\uDF99\\uFE0F\"\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 30,\n    columnNumber: 5\n  }, this);\n}\n_s(VoiceButton, \"I/31IbK0i+bM5IJ1/ONKGYhqEHw=\");\n_c = VoiceButton;\nvar _c;\n$RefreshReg$(_c, \"VoiceButton\");","map":{"version":3,"names":["useState","jsxDEV","_jsxDEV","SpeechRecognition","window","webkitSpeechRecognition","VoiceButton","onResult","_s","listening","setListening","startListening","alert","recognition","lang","start","onresult","event","transcript","results","onerror","className","onClick","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["C:/Users/LENOVO/OneDrive/Documents/Alice/frontend/src/VoiceButton.js"],"sourcesContent":["import { useState } from \"react\";\r\n\r\nconst SpeechRecognition =\r\n  window.SpeechRecognition || window.webkitSpeechRecognition;\r\n\r\nexport default function VoiceButton({ onResult }) {\r\n  const [listening, setListening] = useState(false);\r\n\r\n  const startListening = () => {\r\n    if (!SpeechRecognition) {\r\n      alert(\"Speech Recognition not supported in this browser\");\r\n      return;\r\n    }\r\n\r\n    const recognition = new SpeechRecognition();\r\n    recognition.lang = \"en-US\";\r\n    recognition.start();\r\n    setListening(true);\r\n\r\n    recognition.onresult = (event) => {\r\n      const transcript = event.results[0][0].transcript;\r\n      setListening(false);\r\n      onResult(transcript);\r\n    };\r\n\r\n    recognition.onerror = () => setListening(false);\r\n  };\r\n\r\n  return (\r\n    <button\r\n      className={`mic-button ${listening ? \"listening\" : \"\"}`}\r\n      onClick={startListening}\r\n    >\r\n      üéôÔ∏è\r\n    </button>\r\n  );\r\n}\r\n"],"mappings":";;AAAA,SAASA,QAAQ,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEjC,MAAMC,iBAAiB,GACrBC,MAAM,CAACD,iBAAiB,IAAIC,MAAM,CAACC,uBAAuB;AAE5D,eAAe,SAASC,WAAWA,CAAC;EAAEC;AAAS,CAAC,EAAE;EAAAC,EAAA;EAChD,MAAM,CAACC,SAAS,EAAEC,YAAY,CAAC,GAAGV,QAAQ,CAAC,KAAK,CAAC;EAEjD,MAAMW,cAAc,GAAGA,CAAA,KAAM;IAC3B,IAAI,CAACR,iBAAiB,EAAE;MACtBS,KAAK,CAAC,kDAAkD,CAAC;MACzD;IACF;IAEA,MAAMC,WAAW,GAAG,IAAIV,iBAAiB,CAAC,CAAC;IAC3CU,WAAW,CAACC,IAAI,GAAG,OAAO;IAC1BD,WAAW,CAACE,KAAK,CAAC,CAAC;IACnBL,YAAY,CAAC,IAAI,CAAC;IAElBG,WAAW,CAACG,QAAQ,GAAIC,KAAK,IAAK;MAChC,MAAMC,UAAU,GAAGD,KAAK,CAACE,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAACD,UAAU;MACjDR,YAAY,CAAC,KAAK,CAAC;MACnBH,QAAQ,CAACW,UAAU,CAAC;IACtB,CAAC;IAEDL,WAAW,CAACO,OAAO,GAAG,MAAMV,YAAY,CAAC,KAAK,CAAC;EACjD,CAAC;EAED,oBACER,OAAA;IACEmB,SAAS,EAAE,cAAcZ,SAAS,GAAG,WAAW,GAAG,EAAE,EAAG;IACxDa,OAAO,EAAEX,cAAe;IAAAY,QAAA,EACzB;EAED;IAAAC,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAAQ,CAAC;AAEb;AAACnB,EAAA,CA/BuBF,WAAW;AAAAsB,EAAA,GAAXtB,WAAW;AAAA,IAAAsB,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}