{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\LENOVO\\\\OneDrive\\\\Documents\\\\Alice\\\\frontend\\\\src\\\\App.js\",\n  _s = $RefreshSig$();\nimport { useState, useRef } from \"react\";\nimport \"./App.css\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nexport default function App() {\n  _s();\n  const [status, setStatus] = useState(\"idle\");\n  // idle | listening | speaking\n\n  const recognitionRef = useRef(null);\n  const speechRef = useRef(null);\n  const handleTap = () => {\n    // ðŸ›‘ STOP SPEAKING\n    if (status === \"speaking\") {\n      window.speechSynthesis.cancel();\n      setStatus(\"idle\");\n      return;\n    }\n\n    // ðŸ›‘ STOP LISTENING\n    if (status === \"listening\") {\n      var _recognitionRef$curre;\n      (_recognitionRef$curre = recognitionRef.current) === null || _recognitionRef$curre === void 0 ? void 0 : _recognitionRef$curre.stop();\n      setStatus(\"idle\");\n      return;\n    }\n\n    // ðŸŽ™ï¸ START LISTENING\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!SpeechRecognition) {\n      alert(\"Speech Recognition not supported\");\n      return;\n    }\n    const recognition = new SpeechRecognition();\n    recognition.lang = \"en-US\";\n    recognition.continuous = false;\n    recognition.onresult = e => {\n      const text = e.results[0][0].transcript;\n      askAlice(text);\n    };\n    recognition.onend = () => {\n      if (status === \"listening\") setStatus(\"idle\");\n    };\n    recognitionRef.current = recognition;\n    recognition.start();\n    setStatus(\"listening\");\n  };\n  const askAlice = async text => {\n    setStatus(\"speaking\");\n    try {\n      const res = await fetch(\"http://localhost:8000/chat\", {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify({\n          message: text\n        })\n      });\n      const data = await res.json();\n      speak(data.response);\n    } catch (err) {\n      speak(\"Sorry, something went wrong.\");\n    }\n  };\n  const speak = text => {\n    const utterance = new SpeechSynthesisUtterance(text);\n    utterance.onend = () => setStatus(\"idle\");\n    speechRef.current = utterance;\n    window.speechSynthesis.speak(utterance);\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: [/*#__PURE__*/_jsxDEV(\"img\", {\n      src: \"/bg.jpg\",\n      className: \"bg-image\",\n      alt: \"\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 80,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"h1\", {\n      className: \"title\",\n      children: \"Alice\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 83,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: `orb ${status}`\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 86,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      className: \"mic-btn\",\n      onClick: handleTap,\n      children: [status === \"idle\" && \"Tap to Speak\", status === \"listening\" && \"Listeningâ€¦\", status === \"speaking\" && \"Speakingâ€¦ (tap to stop)\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 89,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 78,\n    columnNumber: 5\n  }, this);\n}\n_s(App, \"lMpVmjHvU9tSieT6XAsx7WJVx50=\");\n_c = App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["useState","useRef","jsxDEV","_jsxDEV","App","_s","status","setStatus","recognitionRef","speechRef","handleTap","window","speechSynthesis","cancel","_recognitionRef$curre","current","stop","SpeechRecognition","webkitSpeechRecognition","alert","recognition","lang","continuous","onresult","e","text","results","transcript","askAlice","onend","start","res","fetch","method","headers","body","JSON","stringify","message","data","json","speak","response","err","utterance","SpeechSynthesisUtterance","className","children","src","alt","fileName","_jsxFileName","lineNumber","columnNumber","onClick","_c","$RefreshReg$"],"sources":["C:/Users/LENOVO/OneDrive/Documents/Alice/frontend/src/App.js"],"sourcesContent":["import { useState, useRef } from \"react\";\nimport \"./App.css\";\n\nexport default function App() {\n  const [status, setStatus] = useState(\"idle\"); \n  // idle | listening | speaking\n\n  const recognitionRef = useRef(null);\n  const speechRef = useRef(null);\n\n  const handleTap = () => {\n    // ðŸ›‘ STOP SPEAKING\n    if (status === \"speaking\") {\n      window.speechSynthesis.cancel();\n      setStatus(\"idle\");\n      return;\n    }\n\n    // ðŸ›‘ STOP LISTENING\n    if (status === \"listening\") {\n      recognitionRef.current?.stop();\n      setStatus(\"idle\");\n      return;\n    }\n\n    // ðŸŽ™ï¸ START LISTENING\n    const SpeechRecognition =\n      window.SpeechRecognition || window.webkitSpeechRecognition;\n\n    if (!SpeechRecognition) {\n      alert(\"Speech Recognition not supported\");\n      return;\n    }\n\n    const recognition = new SpeechRecognition();\n    recognition.lang = \"en-US\";\n    recognition.continuous = false;\n\n    recognition.onresult = (e) => {\n      const text = e.results[0][0].transcript;\n      askAlice(text);\n    };\n\n    recognition.onend = () => {\n      if (status === \"listening\") setStatus(\"idle\");\n    };\n\n    recognitionRef.current = recognition;\n    recognition.start();\n    setStatus(\"listening\");\n  };\n\n  const askAlice = async (text) => {\n    setStatus(\"speaking\");\n\n    try {\n      const res = await fetch(\"http://localhost:8000/chat\", {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify({ message: text }),\n      });\n\n      const data = await res.json();\n      speak(data.response);\n    } catch (err) {\n      speak(\"Sorry, something went wrong.\");\n    }\n  };\n\n  const speak = (text) => {\n    const utterance = new SpeechSynthesisUtterance(text);\n    utterance.onend = () => setStatus(\"idle\");\n    speechRef.current = utterance;\n    window.speechSynthesis.speak(utterance);\n  };\n\n  return (\n    <div className=\"App\">\n      {/* Background */}\n      <img src=\"/bg.jpg\" className=\"bg-image\" alt=\"\" />\n\n      {/* Title */}\n      <h1 className=\"title\">Alice</h1>\n\n      {/* Orb */}\n      <div className={`orb ${status}`} />\n\n      {/* Button */}\n      <button className=\"mic-btn\" onClick={handleTap}>\n        {status === \"idle\" && \"Tap to Speak\"}\n        {status === \"listening\" && \"Listeningâ€¦\"}\n        {status === \"speaking\" && \"Speakingâ€¦ (tap to stop)\"}\n      </button>\n    </div>\n  );\n}\n"],"mappings":";;AAAA,SAASA,QAAQ,EAAEC,MAAM,QAAQ,OAAO;AACxC,OAAO,WAAW;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEnB,eAAe,SAASC,GAAGA,CAAA,EAAG;EAAAC,EAAA;EAC5B,MAAM,CAACC,MAAM,EAAEC,SAAS,CAAC,GAAGP,QAAQ,CAAC,MAAM,CAAC;EAC5C;;EAEA,MAAMQ,cAAc,GAAGP,MAAM,CAAC,IAAI,CAAC;EACnC,MAAMQ,SAAS,GAAGR,MAAM,CAAC,IAAI,CAAC;EAE9B,MAAMS,SAAS,GAAGA,CAAA,KAAM;IACtB;IACA,IAAIJ,MAAM,KAAK,UAAU,EAAE;MACzBK,MAAM,CAACC,eAAe,CAACC,MAAM,CAAC,CAAC;MAC/BN,SAAS,CAAC,MAAM,CAAC;MACjB;IACF;;IAEA;IACA,IAAID,MAAM,KAAK,WAAW,EAAE;MAAA,IAAAQ,qBAAA;MAC1B,CAAAA,qBAAA,GAAAN,cAAc,CAACO,OAAO,cAAAD,qBAAA,uBAAtBA,qBAAA,CAAwBE,IAAI,CAAC,CAAC;MAC9BT,SAAS,CAAC,MAAM,CAAC;MACjB;IACF;;IAEA;IACA,MAAMU,iBAAiB,GACrBN,MAAM,CAACM,iBAAiB,IAAIN,MAAM,CAACO,uBAAuB;IAE5D,IAAI,CAACD,iBAAiB,EAAE;MACtBE,KAAK,CAAC,kCAAkC,CAAC;MACzC;IACF;IAEA,MAAMC,WAAW,GAAG,IAAIH,iBAAiB,CAAC,CAAC;IAC3CG,WAAW,CAACC,IAAI,GAAG,OAAO;IAC1BD,WAAW,CAACE,UAAU,GAAG,KAAK;IAE9BF,WAAW,CAACG,QAAQ,GAAIC,CAAC,IAAK;MAC5B,MAAMC,IAAI,GAAGD,CAAC,CAACE,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAACC,UAAU;MACvCC,QAAQ,CAACH,IAAI,CAAC;IAChB,CAAC;IAEDL,WAAW,CAACS,KAAK,GAAG,MAAM;MACxB,IAAIvB,MAAM,KAAK,WAAW,EAAEC,SAAS,CAAC,MAAM,CAAC;IAC/C,CAAC;IAEDC,cAAc,CAACO,OAAO,GAAGK,WAAW;IACpCA,WAAW,CAACU,KAAK,CAAC,CAAC;IACnBvB,SAAS,CAAC,WAAW,CAAC;EACxB,CAAC;EAED,MAAMqB,QAAQ,GAAG,MAAOH,IAAI,IAAK;IAC/BlB,SAAS,CAAC,UAAU,CAAC;IAErB,IAAI;MACF,MAAMwB,GAAG,GAAG,MAAMC,KAAK,CAAC,4BAA4B,EAAE;QACpDC,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UAAE,cAAc,EAAE;QAAmB,CAAC;QAC/CC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UAAEC,OAAO,EAAEb;QAAK,CAAC;MACxC,CAAC,CAAC;MAEF,MAAMc,IAAI,GAAG,MAAMR,GAAG,CAACS,IAAI,CAAC,CAAC;MAC7BC,KAAK,CAACF,IAAI,CAACG,QAAQ,CAAC;IACtB,CAAC,CAAC,OAAOC,GAAG,EAAE;MACZF,KAAK,CAAC,8BAA8B,CAAC;IACvC;EACF,CAAC;EAED,MAAMA,KAAK,GAAIhB,IAAI,IAAK;IACtB,MAAMmB,SAAS,GAAG,IAAIC,wBAAwB,CAACpB,IAAI,CAAC;IACpDmB,SAAS,CAACf,KAAK,GAAG,MAAMtB,SAAS,CAAC,MAAM,CAAC;IACzCE,SAAS,CAACM,OAAO,GAAG6B,SAAS;IAC7BjC,MAAM,CAACC,eAAe,CAAC6B,KAAK,CAACG,SAAS,CAAC;EACzC,CAAC;EAED,oBACEzC,OAAA;IAAK2C,SAAS,EAAC,KAAK;IAAAC,QAAA,gBAElB5C,OAAA;MAAK6C,GAAG,EAAC,SAAS;MAACF,SAAS,EAAC,UAAU;MAACG,GAAG,EAAC;IAAE;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,eAGjDlD,OAAA;MAAI2C,SAAS,EAAC,OAAO;MAAAC,QAAA,EAAC;IAAK;MAAAG,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAGhClD,OAAA;MAAK2C,SAAS,EAAE,OAAOxC,MAAM;IAAG;MAAA4C,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,eAGnClD,OAAA;MAAQ2C,SAAS,EAAC,SAAS;MAACQ,OAAO,EAAE5C,SAAU;MAAAqC,QAAA,GAC5CzC,MAAM,KAAK,MAAM,IAAI,cAAc,EACnCA,MAAM,KAAK,WAAW,IAAI,YAAY,EACtCA,MAAM,KAAK,UAAU,IAAI,yBAAyB;IAAA;MAAA4C,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC7C,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACN,CAAC;AAEV;AAAChD,EAAA,CA5FuBD,GAAG;AAAAmD,EAAA,GAAHnD,GAAG;AAAA,IAAAmD,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}